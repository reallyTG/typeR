library(drake)


### Name: evaluate_plan
### Title: Use wildcard templating to create a workflow plan data frame
###   from a template data frame.
### Aliases: evaluate_plan

### ** Examples

# Create the part of the workflow plan for the datasets.
datasets <- drake_plan(
  small = simulate(5),
  large = simulate(50)
)
# Create a template workflow plan for the analyses.
methods <- drake_plan(
  regression1 = reg1(dataset__),
  regression2 = reg2(dataset__)
)
# Evaluate the wildcards in the template
# to produce the actual part of the workflow plan
# that encodes the analyses of the datasets.
# Create one analysis for each combination of dataset and method.
evaluate_plan(
  methods,
  wildcard = "dataset__",
  values = datasets$target
)
# Only choose some combinations of dataset and analysis method.
ans <- evaluate_plan(
  methods,
  wildcard = "dataset__",
  values = datasets$target,
  expand = FALSE
)
ans
# For the complete workflow plan, row bind the pieces together.
my_plan <- rbind(datasets, ans)
my_plan
# Wildcards for evaluate_plan() do not need the double-underscore suffix.
# Any valid symbol will do.
plan <- drake_plan(
  numbers = sample.int(n = `{Number}`, size = ..size)
)
evaluate_plan(
  plan,
  rules = list(
    "`{Number}`" = c(10, 13),
    ..size = c(3, 4)
  )
)
# Workflow plans can have multiple wildcards.
# Each combination of wildcard values will be used
# Except when expand is FALSE.
x <- drake_plan(draws = sample.int(n = N, size = Size))
evaluate_plan(x, rules = list(N = 10:13, Size = 1:2))
# You can use wildcards on columns other than "command"
evaluate_plan(
  drake_plan(
    x = target("1 + 1", cpu = "any"),
    y = target("sqrt(4)", cpu = "always"),
    z = target("sqrt(16)", cpu = "any"),
    strings_in_dots = "literals"
  ),
  rules = list(always = 1:2),
  columns = c("command", "cpu")
)
# With the `trace` argument,
# you can generate columns that show how the wildcards
# were evaluated.
plan <- drake_plan(x = sample.int(n__), y = sqrt(n__))
plan <- evaluate_plan(plan, wildcard = "n__", values = 1:2, trace = TRUE)
print(plan)
# With the `trace` argument,
# you can generate columns that show how the wildcards
# were evaluated. Then you can visualize the wildcard groups
# as clusters.
plan <- drake_plan(x = sqrt(n__), y = sample.int(n__))
plan <- evaluate_plan(plan, wildcard = "n__", values = 1:2, trace = TRUE)
print(plan)
cache <- storr::storr_environment()
config <- drake_config(plan, cache = cache)
## Not run: 
##D vis_drake_graph(config, group = "n__", clusters = "1")
##D vis_drake_graph(config, group = "n__", clusters = c("1", "2"))
##D make(plan, targets = c("x_1", "y_2"), cache = cache)
##D # Optionally cluster on columns supplied by `drake_graph_info()$nodes`.
##D vis_drake_graph(config, group = "status", clusters = "up to date")
## End(Not run)



