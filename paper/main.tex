%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{OOPSLA} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{my_style}

\usepackage{listings}

\lstset{ 
  language=R,                     % the language of the code
  basicstyle=\tiny\ttfamily, % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{teal},      % keyword style
  commentstyle=\color{olive},   % comment style
  stringstyle=\color{magenta}      % string literal style
}

\newcommand{\code}[1]{\text{\lstinline[basicstyle=\ttfamily\smaller]~#1~}}

\begin{document}

%% Title information
\title[]{Types for R, Empirically Designed and Evaluated}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
% \titlenote{}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
% \subtitle{}                     %% \subtitle is optional
% \subtitlenote{}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}

\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\section{Introduction}

The story that we're aiming for:
Designing type systems for established languages can be a challenging.
We aim to approach this problem by essentially reverse-engineering a type system from a corpora analysis of a representative subset of R code.
We present a simple type system that captures the vast majority of usage of R --- it is lightweight, and \AT{should provide enough information to be useful to a compiler}.

To evaluate our type system, we present a type-checker that is aware of R's promise semantics. 
In R, function arguments are wrapped in promises such that they are not evaluated until they are needed.
Our tool deals with these promises by inserting a check which fires only when the promise is forced, at which point the value is checked for compliance with the type.

\AT{I can grab some of the intro Jan wrote for the last paper, rework it, and put it here.}

\section{Background}

\AT{I think a lot of the background we can pull from an older version of the paper.
I think both are milling around this directory.}

\subsection{The R Programming Language}

\AT{Introduce the language, and give some context about its user base.}

\begin{lstlisting}
hello <-  "world"
paste(c("this", "is", "some", "code"))
\end{lstlisting}

\subsection{R-dyntrace}
\label{sec:r-dyntrace}

\AT{Worth talking a bit about the analysis framework?}

\subsection{The Corpus}

\AT{This section needs to be tight.
Reviewers were skeptical of CRAN and using the test and example code.
We should convince them otherwise.}

\AT{Some sentences that might be useful:}
We selected packages that have both \AT{a good amount of} reverse dependencies to ensure their broad usefulness, as well \AT{sufficiently high} code and branch coverage of test, example, and vignette programs to ensure that our analysis built up an accurate picture of function use.


%
%
%
%
%
%
\section{Methodology}

%
%
%
%
\subsection{Initial Analysis}

%
%
\subsubsection{Overview}

In order to ensure that our type system design aligns with the day-to-day usage of R, we performed a corpus analysis of some of the most widely used R packages.
We built our dynamic analysis in the R-dyntrace \AT{cite something?} dynamic analysis framework, which is itself built on a modified version of R targeting R version 3.5.0---we refer the reader to Section~\ref{sec:r-dyntrace} for more details on R-dyntrace.

The general idea of the analysis is to intercept calls to functions, builtins, and specials, and collect information on function arguments and returns.
The nature of R is such that all function arguments are wrapped in promises which are only evaluated when the value is actually used.
This could cause issues in a dynamic analysis, as careless use of function arguments can force them early, which can cause unindented side-effects (as these promises are not necessarily pure).
Our analysis deals with this by inspecting the {\it value} slot of these promise objects, which does not force the promise. 
If the value slot contains another promise, we look into its value slot, and so forth until we find a value (or not! in which case, the value is a promise).

Once the value is obtained in this way, we collect the following high-level information about it:
\AT{TODO: need to make the inline code macro and the R listing, and change the tts in here}

\begin{itemize}
\item the result of calling the {\tt typeof} function on the value; in other words, the type that the value has according to R's runtime;
\item its class, which is a list of string class names;
\item its attributes, a list of metadata attached to the value.
\end{itemize}

Now, depending on the ``type'' of the value, we collect further information:
If the value is \ldots

\begin{itemize}
\item one of R's primitive types, we collect its dimension (and if it is a matrix, its dimensions), and if it has a names attribute we collect the names as well;
\item a list, we recursively collect the types of list elements;
\item a list {\it with a names attribute}, we collect the names as well as the types of the slots that those names refer to (data.frames fall into this category);
\item a closure, we simply tag it with a UID computed from the code of the closure as well as its name, which can be later cross-referenced with the analysis results to get a type for the function.
\end{itemize}

Some further miscellaneous information we collect includes:

\begin{itemize}
\item lists which do not contain any NULL elements are qualified with a NULL-free tag; 
\item similarly, vectors which contain no NAs are qualified with a NA-free tag;
\item promises which are never forced throughout function execution are tagged as being {\it metaprogrammed}---this is a common practice in the {\tt tidyverse} suite of packages;
\item formal arguments (arguments which are named in the function definition) which are not passed are recorded as {\it missing}---these represent optional arguments.
\end{itemize}

Now that we've seen the high-level picture of our approach, we will elaborate on some key details on our use of the R-dyntrace framework, and some of the finer points of the analysis.

%
%
\subsubsection{Select Details}

As mentioned, our analysis is built on the R-dyntrace framework.
R-dyntrace is essentially a very efficient instrumentation framework for R, which is built on a modified version of the R runtime.
Fortunately, our dynamic type analysis only needs to be run once, ever---from the analysis results, we synthesize function signatures which are passed along to later type-checking tools which do not rely on a heavily modified runtime. 

We primarily rely on 6 R-dyntrace callbacks: \texttt{closure\_entry}, \texttt{closure\_exit}, \texttt{builtin\_entry}, \texttt{builtin\_exit}, \texttt{special\_entry}, and \texttt{special\_exit}.
These callbacks fire when closures, builtin, and special functions are entered and exited.
In the \texttt{*\_entry} variants, we do some bookkeeping work: the analysis is notified that a closure/builtin/special has been entered by pushing the call onto a stack.
Further, the type of dispatch is recorded: \AT{recall} that there are multiple ways that R performs dynamic dispatch, based on the class of function arguments.
We collect dispatch information in order to analyze dispatch usage patterns.

The main work is done in \texttt{*\_exit} variants.
As arguments to functions in R are wrapped in promises, we delay our reflection to function exit time. 
\AT{Actually, why do we do this?}
In R, promises are essentially objects with value and expression slots.
When a promise is created for a particular expression, that expression is merely put into the expression slot of a promise object, and a special {\it unbound} value is loaded into the value slot.
When the promise is forced, the expression is evaluated in the forcing context, and the value is stored in the value slot of the promise.
So to get the type of a function argument, we check the value slot of the argument promise---perhaps recursively if the value itself is a promise.
If we reach the unbound value, we know the promise was never forced, and thus the argument was unused.

To construct a ``type'' for each argument, we make use of R's C FFI and use low-level machinery to collect type tags and attributes from the R runtime.
At this level, all R values are {\tt SEXP}s with a type tag that can be obtained using the {\tt TYPEOF} function from the C FFI.
In certain circumstances, such as when {\tt TYPEOF} indicates that a value is a primitive, we perform additional reflection e.g. on the length (with {\tt LENGTH}) and also vector element names (through a call to {\tt getAttrib(the\_value, R\_NamesSymbol)}).

\subsection{Implementation}

\AT{Talk about how the type system was implemented, in terms of the checks, how they work, how they are performed by the runtime, etc.}

\subsection{Evaluation}

\AT{Talk about Aviral's work on evaluation.}

\section{Type System Design}

\AT{Lay out the type system.
Ideally, for every interaction we propose, we should be able to point to an analysis that supports our claim.
Maybe we don't always have to do this, especially for some of the simple, obvious types, but any departures from basic R functionality should be supported by the data.}

\section{Evaluation Results}

\AT{The decisions we made when coming up with the types will be validated in the last section.
This section is for determining how effective the type system is.
We have two evaluation strategies currently: comparing against reverse dependencies, and comparing against the Kaggle programs.}

\section{Related Work}

\AT{Good to mention the related projects, e.g. how this was undertaken in other languages, like Ruby.
There's a lot of literature in that space I think, I've read some of it but not all.
We also have some related work in the old paper, I'll grab it and put it here.}

\section{Conclusion}

\ldots

\subsection{Threats to Validity}

\ldots

\subsection{Future Work}

\ldots

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
%\bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
