%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{OOPSLA} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{my_style}

\usepackage{listings, wrapfig}

\lstset{ 
  language=R,                     % the language of the code
  basicstyle=\tiny\ttfamily, % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{teal},      % keyword style
  commentstyle=\color{olive},   % comment style
  stringstyle=\color{magenta}      % string literal style
}

\newcommand{\code}[1]{\text{\lstinline[basicstyle=\ttfamily\smaller]~#1~}}

% Macros for type names from the old paper.
\newcommand{\attr}[2]{\ensuremath{#1_{\mathtt{#2}}}\xspace}
\newcommand{\attrclass}[3]{\ensuremath{#1^{\mathtt{#3}}_{\mathtt{#2}}}\xspace}
\renewcommand{\to}{\ensuremath{\rightarrow}\xspace}
\newcommand{\D}{\ensuremath{\small\vec{\mathtt D}}\xspace} % Double
\newcommand{\I}{\ensuremath{\small\vec{\mathtt I}}\xspace} % Integer
\renewcommand{\C}{\ensuremath{\small\vec{\mathtt C}}\xspace} % Character
\renewcommand{\L}{\ensuremath{\small\vec{\mathtt L}}\xspace} % Logical
\newcommand{\R}{\ensuremath{\small\vec{\mathtt R}}\xspace} % Raw
\newcommand{\X}{\ensuremath{\small\vec{\mathtt X}}\xspace} % Complex
\newcommand{\Y}{\ensuremath{\small\vec{\mathtt Y}}\xspace} % Symbol
\newcommand{\sY}{\ensuremath{\small{\mathtt Y}}\xspace} % Symbol
\newcommand{\sS}{\ensuremath{\small{\mathtt S}}\xspace} % S4
\newcommand{\sF}{\ensuremath{\small{\mathtt F}}\xspace} % Closure
\newcommand{\sE}{\ensuremath{\small{\mathtt E}}\xspace} % Env
\renewcommand{\R}{\ensuremath{\small\vec{\mathtt R}}\xspace} % Raw
\newcommand{\sN}{\ensuremath{\small{\mathtt N}}\xspace}     % Null
%\renewcommand{\l}{\ensuremath{\small L<?>}\xspace}     % List
\renewcommand{\l}{\ensuremath{\small\underline{\mathtt ?}}\xspace}     % List
\newcommand{\sD}{\ensuremath{\small{\mathtt D}}\xspace} % Double
\newcommand{\sI}{\ensuremath{\small{\mathtt I}}\xspace} % Integer
\newcommand{\sC}{\ensuremath{\small{\mathtt C}}\xspace} % Character
\newcommand{\sL}{\ensuremath{\small{\mathtt L}}\xspace} % Logical
\newcommand{\sX}{\ensuremath{\small{\mathtt X}}\xspace} % Complex
\newcommand{\sR}{\ensuremath{\small{\mathtt R}}\xspace} % Raw
\newcommand{\ANY}{\ensuremath{\small{\mathtt ?}}\xspace}     % Any
\newcommand{\lT}[1]{\ensuremath{\small\underline{\mathtt{#1}}}\xspace}     % list<T>
\newcommand{\M}[1]{\ensuremath{\attr{\vec{\tt #1}}{mat}}\xspace}     % matrix
\newcommand{\df}{\ensuremath{\attr{\l}{df}}\xspace}     % data.frame



\begin{document}

%% Title information
\title[]{Types for R, Empirically Designed and Evaluated}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
% \titlenote{}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
% \subtitle{}                     %% \subtitle is optional
% \subtitlenote{}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}

\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\section{Introduction}

The story that we're aiming for:
Designing type systems for established languages can be a challenging.
We aim to approach this problem by essentially reverse-engineering a type system from a corpora analysis of a representative subset of R code.
We present a simple type system that captures the vast majority of usage of R --- it is lightweight, and \AT{should provide enough information to be useful to a compiler}.

To evaluate our type system, we present a type-checker that is aware of R's promise semantics. 
In R, function arguments are wrapped in promises such that they are not evaluated until they are needed.
Our tool deals with these promises by inserting a check which fires only when the promise is forced, at which point the value is checked for compliance with the type.

\AT{I can grab some of the intro Jan wrote for the last paper, rework it, and put it here.}

%
%
%
%
%
%
\section{Background}

In this section, we will introduce the R programming language, as well as discuss the dynamic analysis framework we used as part of our initial analysis.

%
%
%
%
\subsection{The R Programming Language}

Over the last decade, the R Project has become a key tool for implementing
sophisticated data analysis algorithms in fields ranging from Computational
Biology~\cite{R05} to Political Science~\cite{R:Keele:2008}. At the heart of
the R project is a \emph{vectorized, dynamic, lazy, functional,
  object-oriented} programming language with a rather unusual combination of
features~\cite{ecoop12} designed to ease learning by non-programmer and
enable rapid development of new statistical methods.  The language, commonly
referred to as R was designed in 1993 by Ross Ihaka and Robert
Gentleman~\cite{R96} as a successor to S~\cite{S88}.  First released in
1995, under a GNU license, R rapidly became the lingua franca for
statistical data analysis. Today, there are over 13,000 R packages available
from repositories such as CRAN and Bioconductor.  With 55 R user groups
world-wide, Smith~\cite{eco11} estimates that there are over 2 million
end-users.

As an introduction to R, consider the code snippet in Fig.~\ref{sample} from
a top-level interaction where the user defines a function \code{normSum}
that accepts vectors of integers, logicals, doubles and complex values and
normalizes the vector with respect to its sum and rounds the results. The
function definition does not require type annotations, and all operations
transparently work on vectors of any length and different types.

\begin{figure}[!hb]{\small
\begin{lstlisting}
> normSum <- function( m )  round( m / sum(m), 2)
> normSum(c(1L,3L,6L))
[1] 0.1 0.3 0.6
> normSum(c(1.1,3.3,6.6))
[1] 0.1 0.3 0.6
> normSum(c(1.6,3.3,6.1))
[1] 0.15 0.30 0.55
> normSum(complex(r=rnorm(3),i=rnorm(3)))
[1] 0.49+0.21i 0.30-0.18i 0.22-0.03i
\end{lstlisting}}
\caption{Sample R code}\label{sample}
\end{figure}

In R, function can be called with named parameters, R support variable
argument lists, and arguments can have default values. Putting all of these
together consider the following declaration:

\begin{lstlisting}
f <- function(x, ..., y=3) x + y
\end{lstlisting}

\noindent
Function \k{f} can be called with a single argument \code{f(3)}, with named
argument \code{f(y=4,x=2)} and with a variable number of arguments,
\code{f(1,2,3,4,y=5)}, all of these calls will return \code{6}.

R has a number of features that are not crucial to the present
discussion. We will mention some of them here for completeness.  In R, data
structures are reference counted and have copy-on-write semantics, thus the
assignment \code{x[12]<-3} results in an update to a copy of \code{x} unless
the reference count on that object is 1.  This semantics gives R a
functional flavor while allowing updating in place within loops (the first
update copies, subsequent updates are performed on the copy). Arguments to
functions are evaluated only when needed, they are bundled in so-called
promises which package the original expression (as an abstract syntax tree, or AST), its environment
as well as the result of evaluating the expression. Promises can be
leveraged for meta-programming as it is possible to retrieve the text of a
promise and evaluate it in a different environment.


\subsubsection{Types of Data}
\label{subsubsec:backgroundtypes}

Before attempting to define a type system for R, we should understand the
different kinds of values that programs operate on.  As we will see
different notions of type may emerge depending on how granular we want to
be.

\renewcommand{\k}[1]{{\tt #1}\xspace}

R has one builtin notion of type that can be queried by the \k{typeof}
function. Over the years, programmers have found the need for a richer type
structure and have added {\it attributes}. The best way to think of attributes is
as an optional map from name to values that can be attached to any object.
Attributes are used to encode various type structures. They can be queried
with functions such as \k{attributes} and \k{class}.

\begin{wrapfigure}{r}{6.1cm}
\footnotesize\begin{tabular}{l|c|l@{}}\hline
\multicolumn{3}{l}{\bf Vectorized data types:}  \\\hline
\k{logical}   & \L & vector of boolean values\\
\k{integer}   & \I & vector of 32 bit integer values\\
\k{double}    & \D & vector of 64 bit floating points\\
\k{complex}   & \X & vector of complex values\\
\k{character} & \C & vector of strings values\\
\k{raw}       & \R & vector of bytes\\
\k{list}      & \l & vector of values of any type\\\hline
\multicolumn{3}{l}{\bf Scalar data types:}\\\hline
\k{NULL}      & \sN &  singleton null value\\
\k{S4}        & \sS &  instance of a S4 class \\
\k{closure}   & \sF & a function with its environment\\
\k{environment}&\sE &  a mapping from symbol to value \\\hline
\multicolumn{3}{l}{\bf Implementation data types:}\\\hline
\multicolumn{3}{l}{\k{special},
\k{builtin},
\k{symbol} (\sY),
\k{pairlist},
\k{promise}}\\
\multicolumn{3}{l}{
\k{language},
\k{char},
\k{...},
\k{any},
\k{expression},
}\\
\multicolumn{3}{l}{
\k{externalprt},
\k{bytecode},
\k{weakref}}\\\hline
\end{tabular}\caption{Builtin Types}\label{types}\end{wrapfigure}

Figure~\ref{types} lists all of the builtin types that are provided by the
language. They are the possible return values of \k{typeof}. There is no
intrinsic notion of subtyping in R. But, in many context a \k{logical} will
convert to \k{integer}, and an \k{integer} will convert to \k{double}.  Some
off conversion can occur in corner cases, such as \k{1<"2"} holds and
\k{c(1,2)[1.6]} returns the first element of the vector, as the double is
converted to an integer. R does not distinguish between scalars and vectors
(they are all vectors), so \code{typeof(5) ==} \code{typeof(c(5)) ==
  typeof(c(5,5))} \code{ == "double"}. Finally all vectorized data types have a
distinguished missing value denoted by \code{NA}. The default type of
\code{NA} is \k{logical}. We can see that \code{typeof(NA)=="logical"}, but
NA inhabits every type: \code{typeof(c(1,NA)[2])=="double"}.

With one exception all vectorized data types are monomorphic, the exception
is the \k{list} type which can hold values of any other type including
\k{list}. For all monomorphic data types, attempting to store a value of a
different type will cause a conversion. Either the value is converted to the
type of vector, or the vector is converted to the type of the value.

Scalar data types include the distinguished \k{NULL} value, which is also of
type \k{NULL}, instance of classes written using the S4 object system,
closures and environments.  The implementation of R has a number of other
types that are mostly not used by user code, they are listed in
Figure~\ref{types} for reference.

The addition of attributes lets programmers extend the set of types by
tagging data with user-defined attributes. For example, one could define a
vector of four values, \code{x<-c(1,2,3,4)} and then attach the attribute
\k{dim} with a pair of numbers as value: \code{attr(x,"dim")<-c(2,2)}.  From
that point, arithmetic functions will treat \k{x} as a 2x2 matrix. Another
attribute that can be set is the \k{class}.  This attribute can be bound to
a list of class names. For instance, \code{class(x)<-"human"}, set the class
of \k{x} to be \k{human}.  Attributes are thus used for object-oriented
programming. The S3 object system support single dispatch on the class of
the first argument of a function, whereas the S4 object system allows
multiple dispatch (on all arguments). Some of the most widely used data
type, such as data frames, leverage attributes. A data frame, for instance,
is a list of vectors with a class and a column name attribute.

\paragraph{Summary.} The most common values in R computations are vectorized
types. R programs do not have a way to constrain values to be scalar.
\k{NULL} is sometimes used to represent the case when no value is
available. \k{NA} is used within vector to represent missing observations.
Attributes can decorate values and are used as building blocks for
object-oriented programming. A potential type system for R could focus only
on the builtin types, if one wanted to strive for simplicity, or it could
try to capture attributes at the risk of increased complexity.

%
%
%
%
\subsection{R-dyntrace}
\label{sec:r-dyntrace}

\AT{Leaving this one for Aviral.}

R-dyntrace is an efficient dynamic analysis framework for R.

\subsection{contractr}
\label{sec:contractr}
\emph{contractr} is an R package that implements our type system for the R
package ecosystem. It adds contracts to package functions for type-checking
arguments and results on function calls. On contract failure, it reports a type
mismatch warning with the package name, function name, argument name, argument
position, expected type signature, actual type signature of the value observed,
and a stack trace for the called function. \emph{contractr} works by modifying
function definition to insert a call to the type-checking function. When the
modified function is called, the type-checking function is invoked on the
modified function's arguments and return value.

\emph{contractr} is implemented in 434 R LOC and 2358 C++ LOC. The core
implementation is in C++ to keep the runtime overhead low. It been designed and
tested with GNU R-3.5.0 but it also works with recent versions of R. It has been
hardened with a battery of 400 test cases. We have used it extensively during
the course of this work; firstly, for sanity checking of XXX type signatures
generated for the XXX packages during the development phase, and secondly, for
assessing the quality of these type signatures on XXX packages during the
evaluation phase.

%
%
\subsubsection{Type Declarations}
Type declarations can be made available to \emph{contractr} in three ways: as
part of its internal database of types (which already has type signatures for
our corpus of 500 packages), as part of a designated \emph{TYPEDECLARATION} file
supplied by the package author and installed along with the package, or through
a user-level API function insert\_contract that lets the user insert contract to
a custom function with the type declaration provided as a string argument.

%
%
\subsubsection{Challenges}
Retrofitting a robust and efficient type-system as an external package in R has
been a significant undertaking. We had to contend with the complex design
choices of R to make it work without surprises for the end-users. We describe
two key challenges that we faced in the development of \emph{contractr}.
Firstly, we faced the problem of type-checking arguments in a non-strict
language while retaining the non-strict semantics. When a function is called in
R, parameters are bound to unevaluated code thunks called
promises~\cite{oopsla19}, instead of values which can be immediately
type-checked. Naively forcing promises at function call to obtain a value for
type-checking would violate the language semantics, leading to incorrect
results. To preserve the original semantics, \emph{contractr} modifies the
promise by wrapping the unevaluated promise expression in a call to its
type-checker along with the context necessary to associate the promise to the
function and its parameter (for failure messages). The contract checking happens
when the promise is evaluated, either inside the function or many calls deep.
This works, but with one wrinkle. GNU R has a bytecode compiler that can
sometimes optimize away promises; in those cases, \emph{contractr} receives
values that can be immediately type-checked. Non-strict semantics dictate that
any computation related to the argument should happen on the first use of the
argument. So type-checking at this point and issuing an error message would
violate the non-strict semantics; if this argument is never used, it would be
incorrect to type-check it at the beginning of call. To make this work,
\emph{contractr} mutates the function parameter binding to a promise that wraps
the argument value in a call to the type-checker, as in the previous case.
Secondly, we faced the problem of type-checking function return value. In R, the
result of a function call is the result of evaluating the last expression in the
function body; so an explicit return call is absent from most function
definitions. Thus, there could be many potential sub-expressions in the function
body which need to be type-checked aginst the return type. To address this,
\emph{contractr} registers the type-checker to be called on the return value
through a function exit hook. This hook is executed in the function call's
environment after it has executed. While this works, we have to contend with yet
another wrinkle, R interpreter can perform longjumps in its C implementation,
which causes active R function calls on the stack to be discarded. When they are
discarded, their exit hooks are called, which in this case calls the registered
type-checker. But, these functions are in the middle of an active computation,
so they don't have a return value to type-check. \emph{contractr} deals with
this problem by allocating a unique sentinel object which serves as the return
value for calls that are discarded. The function call exit hook does not call
the type-checker if this unique value happens to be the return value of the
call.

%
%
\subsubsection{Usability}
Through this package, we intend to provide a clear path for the R developers to
add types to untyped package code. Hence, we have paid a lot of attention to
usability in its design. Firstly, the package enables type-checking for all
packages with type signatures, automatically, on importing, offering a seamless
and hassle-free experience for both package developers and end-users. A mere
library(\emph{contractr}) is enough to insert contracts, both, in packages
pre-loaded in the user's workspace and in packages that will be loaded
eventually. For this, \emph{contractr} relies heavily on R's reflective and
dynamic capabilities. Upon loading \emph{contractr} scans all the pre-loaded
packages in the user's workspace and inserts contracts in functions for which
type signatures are available. For all other packages installed on user's
machine but not yet loaded in the workspace, contractr sets up package load
hooks. The hooks get executed when these packages get loaded and insert
contracts to the package functions. The ensures that users do not fiddle
manually with the \emph{contractr} API to enable type-checking for packages
loaded eventually. Furthermore, \emph{contractr} automatically removes contracts
from all the package functions and restores them to their original state when it
is unloaded, an operation that is rarely performed but is possible, nonetheless.
Secondly, we enable package authors to supply type declarations to
\emph{contractr} for their package functions, without requiring any modification
to package code. This is accomplished by providing type declarations inside
roxygen2 function comment blocks. roxygen2 is an R package that enables authors
to add documentation to R functions in the form of organized plaintext sections
which are automatically exported to R's latex style custom documentation format.
roxygen2 is used by … R packages in CRAN. It also provides an extension API for
processing metadata in custom documentation tag sections. A package can register
a method to be called when this tag is encountered. The metadata for that tag
section is made available to the registrant before package build and
installation steps. \emph{contractr} uses this API to implement a @type tag. Our
roxygen2 hook extracts type declarations from these sections from all the
documented functions of the package and stores then in a TYPEDECLARATION file
inside the package folder. This files is copied as is on package installation
and automatically picked up \emph{contractr} when the two packges are loaded.
Here is an example of how a roxygen code block looks like with our type
declaration:


This technique enables the function and its type signature to coexist next to
each other, where they are more likely to remain synchronized. It also enables
package authors to use our type system without modifying their code. Thirdly, we
provide a very expressive API and package switches to the users, covering a
variety of uses cases. During development, developers can explicitly insert
contracts by supplying the type declaration as a string argument to the
insert\_contract API function. Contracts can be removed by calling
remove\_contract on a function. Contracts can be selectively enabled or disabled
for code blocks by wrapping them in calls to ignore\_contracts and
capture\_contracts functions. This enables developers and users to selectively
type check sections of code. Furthermore, these functions return a data frame
that contains all the information about failed and successful contract
assertions in the wrapped code blocks. Multiple type-checking failures can
introduce a lot of noise in the program output. To alleviate this problem, users
can set a flag, \emph{contractr}.severity, to “silence” which suppresses the
failure messages. The contract assertions can then be obtained as a data frame
through a call to get\_contracts at any program point. Setting this flag to
“error” will turn the type-checking failure warnings to errors.

%
%
%
%
\subsection{The Corpus}

\AT{This section needs to be tight.
Reviewers were skeptical of CRAN and using the test and example code.
We should convince them otherwise.}

\AT{Some sentences that might be useful:}
We selected packages that have both \AT{a good amount of} reverse dependencies to ensure their broad usefulness, as well \AT{sufficiently high} code and branch coverage of test, example, and vignette programs to ensure that our analysis built up an accurate picture of function use.

%
%
\subsubsection{Cross-Validation Against Kaggle}

Kaggle is a website offering an environment for hosting Jupyter notebooks, and importantly provides access to a large number of open-source data sets and R and Python code.
This solved a major issue with R programs hosted on e.g. Github, where often the data is not made available.
Our aim is to run R programs hosted on Kaggle to validate the type signatures we generated for popular R packages.

\AT{Anything else to say on Kaggle, here? We will probably talk more about the corpus we analyzed later.}

%
%
%
%
%
%
\section{Methodology}

%
%
%
%
\subsection{Initial Analysis}

%
%
\subsubsection{Overview}

In order to ensure that our type system design aligns with the day-to-day usage of R, we performed a corpus analysis of some of the most widely used R packages.
We built our dynamic analysis in the R-dyntrace~\cite{oopsla19} dynamic analysis framework, which is itself built on a modified version of R targeting R version 3.5.0---we refer the reader to Section~\ref{sec:r-dyntrace} for more details on R-dyntrace.

The general idea of the analysis is to intercept calls to functions, builtins, and specials, and collect information on function arguments and returns.
The nature of R is such that all function arguments are wrapped in promises which are only evaluated when the value is actually used.
This could cause issues in a dynamic analysis, as careless use of function arguments can force them early, which can cause unindented side-effects (as these promises are not necessarily pure).
Our analysis deals with this by only inspecting the value of an argument when the argument is forced, and if it is never forced we make note of that by ascribing the type {\tt ???}.

% Our analysis deals with this by inspecting the {\it value} slot of these promise objects, which does not force the promise. 
% If the value slot contains another promise, we look into its value slot, and so forth until we find a value (or not! in which case, the value is a promise).

Once the value is obtained in this way, we collect the following high-level information about it:
\AT{TODO: need to make the inline code macro and the R listing, and change the tts in here}

\begin{itemize}
\item the result of calling the {\tt typeof} function on the value; in other words, the type that the value has according to R's runtime;
\item its class, which is a list of string class names;
\item its attributes, a list of metadata attached to the value.
\end{itemize}

Now, depending on the ``type'' of the value, we collect further information:
If the value is \ldots

\begin{itemize}
\item one of R's primitive types, we collect its dimension (and if it is a matrix, its dimensions), and if it has a names attribute we collect the names as well;
\item a list, we recursively collect the types of list elements;
\item a list {\it with a names attribute}, we collect the names as well as the types of the slots that those names refer to (data.frames fall into this category);
\item a closure, we simply tag it with a UID computed from the code of the closure as well as its name, which can be later cross-referenced with the analysis results to get a type for the function.
\end{itemize}

Some further miscellaneous information we collect includes:

\begin{itemize}
\item lists which do not contain any NULL elements are qualified with a NULL-free tag; 
\item similarly, vectors which contain no NAs are qualified with a NA-free tag;
\item promises which are never forced throughout function execution are tagged as being {\it metaprogrammed}---this is a common practice in the {\tt tidyverse} suite of packages;
\item formal arguments (arguments which are named in the function definition) which are not passed are recorded as {\it missing}---these represent optional arguments.
\end{itemize}

Now that we've seen the high-level picture of our approach, we will elaborate on some key details on our use of the R-dyntrace framework, and some of the finer points of the analysis.

%
%
\subsubsection{Select Details}

As mentioned, our analysis is built on the R-dyntrace framework.
R-dyntrace is a very efficient instrumentation framework for R, which is built on a modified version of the R runtime.
Our dynamic type analysis only needs to be run once, ever---from the analysis results, we synthesize function signatures which are passed along to later type-checking tools which do not rely on a heavily modified runtime. 

We primarily rely on 8 R-dyntrace callbacks: \texttt{closure\_entry}, \texttt{closure\_exit}, \texttt{builtin\_entry}, \texttt{builtin\_exit}, \texttt{special\_entry},\texttt{special\_exit}, \texttt{promise\_force\_entry}, and \texttt{promise\_force\_exit}.
These callbacks fire when closures, builtin, and special functions are entered and exited, and before and after the forcing of promises.
The function-related callbacks are used mainly for bookkeeping: the analysis is notified that a closure/builtin/special has been entered/exited by pushing/popping the call onto a stack.
The calls themselves store a {\it call trace} object, where we store the type information that we collect.
Further, the type of dispatch is recorded on the {\tt \_entry} variants: \AT{recall} that there are multiple ways that R performs dynamic dispatch, based on the class of function arguments.
We collect dispatch information in order to analyze dispatch usage patterns.

The main work is done in {\tt promise\_force\_exit}.
As arguments to functions in R are wrapped in promises, we delay our reflection to promise force time.
In R, promises are essentially objects with value and expression slots.
When a promise is created for a particular expression, that expression is merely put into the expression slot of a promise object, and a special {\it unbound} value is loaded into the value slot.
When the promise is forced, the expression is evaluated in the forcing context, and the value is stored in the value slot of the promise.
So to get the type of a function argument, we check the value slot of the argument promise---perhaps recursively if the value itself is a promise.
On function {\tt \_exit} variants, we deal with situations where an argument was never used (and thus never forced): these show up as missing slots in the call trace object, and we ascribe them the type {\tt ???}.

To construct a ``type'' for each argument, we make use of R's C FFI and use low-level machinery to collect type tags and attributes from the R runtime.
At this level, all R values are {\tt SEXP}s with a type tag that can be obtained using the {\tt TYPEOF} function from the C FFI.
In certain circumstances, such as when {\tt TYPEOF} indicates that a value is a primitive, we perform additional reflection e.g. on the length (with {\tt LENGTH}) and also vector element names (through a call to {\tt getAttrib(the\_value, R\_NamesSymbol)}).

\subsection{Implementation}

\AT{Talk about how the type system was implemented, in terms of the checks, how they work, how they are performed by the runtime, etc.}

\subsection{Evaluation}

\AT{Talk about the evaluation.}

\AT{Ok, so we haven't discussed the story for the results, so I'll just write some disjointed sections, discussing design decisions, and backing them up with the data.
This should give us an idea of what we want to say, and we can decide how to organize everything once we have stuff written.
Some of the things I'll be pulling from the data are: how many functions are higher-order? How many times are structs present? How many times do classes supercede other types?
Basically, we want to use this section to turn the simplicity of our type system from a weakness into a strength. 
The simplicity {\it is} a strength, we just need to make sure that's obvious to the reviewer.}

%
%
%
%
%
%
\section{Type System Design}
\label{sec:typesystemdesign}

Our corpora analysis reported \AT{number} call traces for over \AT{number} functions.
We distilled these call traces into function types which captured the dynamic behaviour of the functions.
We emphasize that this was an iterative process: initial analysis suggested a certain set of types, which we tried and implemented, and further analysis suggested improvements, and so on.
In this section, we will present the final type system that we designed, which we believe captures the essence of R.
Throughout, we will touch on design decisions and weigh our choices against alternatives, speaking to the strengths and weaknesses of our chosen design.

%
%
%
%
\subsection{Basic Types}
\label{subsec:basictypes}

As discussed in Section~\ref{subsubsec:backgroundtypes}, the workhorse types in R are the vectorized primitives: integers, doubles, complex numbers, logicals (booleans), characters, and raws (bytes).
These are {\it vectorized} in that they are always considered to be vectors by the R runtime: for instance, even ``scalar'' numbers are considered to be unit-length vectors to R.
These primitive vectors are homogeneous, in that a vector of doubles contains only doubles.

Related to these primitive types is one of R's notions of ``nullness'': for each of the primitives, R distinguishes a special ``NA'' value which represents missing data.
There is an NA for each of the primitive types (i.e. there is a double NA, integer NA, etc.).
Thus, even homogeneous vectors can represent missing data with their appropriate NA value.

As with everything in R, there is nuance in even the simplest cases.
We will now discuss our design decisions relating to the vectorized primitives.

%
%
\subsubsection{Possibly-NA Primitives}

A common primitive usage pattern is related to the presence of NAs: \AT{often}, programmers explicitly check for NAs in primitive vectors, possibly sanitizing them if they are present.
For instance, consider the code in \AT{do an NA example}.
NAs complicate practically every computation using primitive vectors, a fact that many programmers appear to be acutely aware of.

%
%
\subsubsection{Scalar Primitives}

\AT{Maybe we combine the next 3 subsections into one on dimensionality? There are overlapping arguments.}
Initial analyses of our data revealed that programmers \AT{often} use scalars (as explicitly as they can, anyway).
For example, consider the code in \AT{do a scalar example}.

We found that scalars occurred more often than vectors, and chose the scalar type syntax as the default.
The syntax for primitive scalars and vectors is as follows:

\AT{syntax...}
 
%
%
\subsubsection{Forgoing Matrices}

Another layer of complexity on vectorized primitives is the presence of ``matrices'', which are \AT{more detail}.
To R, a vector is a single-dimensional matrix, and R coerces vectors to matrices where appropriate.
That said, if all vectors are matrices, then any computation that is valid on a matrix should also be valid on a vector.
Restrictions on matrix-types arguments amount to restrictions on the dimensions of the argument, which suggests a dependent type system.
We will touch on this shortly.
\AT{I can try to come up with some numbers, here. I'm open to a discussion on how best to word this.}
 
%
%
\subsubsection{Forgoing Dimensionality} 

\AT{Will revisit to tighten discussion, need to think about best way to phrase this.
Perhaps "dependent type system bad" is enough?}
Including data dimensions in types would make our type system a dependent type system, which we believe is too complex to retrofit onto a dynamic data science language such as R.
The simplest way to include dimensions would be to explicitly specify the dimensions of an argument (e.g. specifying that a function should always be called with a double vector of length 10), which is not particularly useful, and a pattern which \AT{rarely appeared in our analysis}.



%
%
%
%
\subsection{Lists}

%
%
%
%
%
%
\section{Evaluation Results}

\AT{The decisions we made when coming up with the types will be validated in the last section.
This section is for determining how effective the type system is.
We have two evaluation strategies currently: comparing against reverse dependencies, and comparing against the Kaggle programs.}

\section{Related Work}

\AT{Good to mention the related projects, e.g. how this was undertaken in other languages, like Ruby.
There's a lot of literature in that space I think, I've read some of it but not all.
We also have some related work in the old paper, I'll grab it and put it here.}

\section{Conclusion}

\ldots

\subsection{Threats to Validity}

\ldots

\subsection{Future Work}

\ldots

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bib/biblio,bib/jv,bib/r,bib/new,bib/gradual}

%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
